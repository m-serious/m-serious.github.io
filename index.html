<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> <strong>Zijia</strong> Liu (刘子嘉) </title> <meta name="author" content="Zijia Liu"> <meta name="description" content="A PhD student at Tongji University and a visiting scholar at the University of Illinois Urbana-Champaign (UIUC), focusing on Agentic AI and Multimodal Representation Learning. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/ZL_icon.jpg?9ffda2718189f58e51e38ddbc3d1a934"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://m-serious.github.io/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="https://drive.google.com/file/d/1_fKAusPmqkLvKxWHBygeUA0Se-cFrVFz/view?usp=sharing" rel="external nofollow noopener" target="_blank">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <strong>Zijia</strong> Liu (刘子嘉) </h1> <p class="desc">Email: zliu331[at]illinois[dot]edu</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?85895db1851bf79abc049bada375722f" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>PhD Candidate in Tongji</p> <p>Visiting Scholar in UIUC NLP</p> <p>Agentic AI, Multimodal LLMs</p> </div> </div> <div class="clearfix"> <p>I am a PhD student at Tongji University, advised by Prof. Gang Yan, and a visiting researcher at the University of Illinois Urbana-Champaign (UIUC), advised by Prof. <a href="https://blender.cs.illinois.edu/hengji.html" rel="external nofollow noopener" target="_blank">Heng Ji</a>, Prof. <a href="https://siebelschool.illinois.edu/about/people/faculty/dilek" rel="external nofollow noopener" target="_blank">Dilek Hakkani-Tur</a>, and Prof. <a href="https://cs.stanford.edu/people/jiaxuan/" rel="external nofollow noopener" target="_blank">Jiaxuan You</a>. My research is centered on pushing the boundaries of what Large Language Models (LLMs) can achieve, with a focus on building more capable, general, and responsible AI agents through advanced Reinforcement Learning.</p> <p>My recent achievement is leading the <a href="https://arxiv.org/abs/2505.13508" rel="external nofollow noopener" target="_blank">Time-R1</a> project, where my novel RL framework empowered a 3B model to outperform models 200x larger on challenging temporal reasoning benchmarks. This work underscores my expertise in creating highly efficient training pipelines that prioritize sophistication over sheer scale.</p> <p>My experience also includes:<br> • Architecting general-purpose agent frameworks like <a href="https://github.com/FoundationAgents/OpenManus" rel="external nofollow noopener" target="_blank">OpenManus</a> to enhance strategic planning and generalization.<br> • Integrating robust safety and ethical layers into AI scientist agents through the <a href="https://arxiv.org/abs/2505.23559" rel="external nofollow noopener" target="_blank">SafeScientist</a> framework.<br> • Designing <a href="https://arxiv.org/abs/2505.22961" rel="external nofollow noopener" target="_blank">persuasive agents</a> with Theory of Mind to improve their interaction capabilities.</p> <p>Core Competencies:<br> • Agentic AI: Reasoning, Planning, Memory, Generalization <br> • Reinforcement Learning: Online/Offline RL, Reward Engineering, Curriculum Learning<br> • LLM Specializations: Multimodality (LVLM), Temporal Reasoning, Persuasive AI, AI Safety</p> <p>I am passionate about engaging with fellow researchers and practitioners. I am always open to discussing new research, challenges, and potential collaborations!</p> <p><span style="color: red;">I am a PhD candidate expecting to graduate in Winter 2026 and am beginning my search for full-time roles. If you believe I might be a good fit for your institution or organization, I’d love to connect!</span></p> <h2 id="awards">awards</h2> <p>• <strong>2024</strong> - National Scholarship for Doctoral Students (Top 1%)<br> • <strong>2024</strong> - Excellent student of Tongji University (Top 1%)</p> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/Time-R1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Time-R1.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="liu2025time" class="col-sm-8"> <div class="title">Time-R1: Towards Comprehensive Temporal Reasoning in LLMs</div> <div class="author"> <strong>Zijia Liu</strong>, Peixuan Han, Haofei Yu, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Haoru Li, Jiaxuan You' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2505.13508</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2505.13508" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://b23.tv/aArKNSY" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/ulab-uiuc/Time-R1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://drive.google.com/file/d/1c4Ob3VFbSAdJkXIdEAqY9jzTXjlc8nUj/view?usp=drive_link" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> <a href="https://huggingface.co/collections/ulab-ai/time-r1-682626aea47cb2b876285a16" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Model</a> <a href="https://huggingface.co/datasets/ulab-ai/Time-Bench" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Dataset</a> <a href="https://mp.weixin.qq.com/s/HOG8Es3sefi91f7XoMDhNQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Coverage</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Large Language Models (LLMs) demonstrate impressive capabilities but lack robust temporal intelligence, struggling to integrate reasoning about the past with predictions and plausible generations of the future. Meanwhile, existing methods typically target isolated temporal skills, such as question answering about past events or basic forecasting, and exhibit poor generalization, particularly when dealing with events beyond their knowledge cutoff or requiring creative foresight. To address these limitations, we introduce <em>Time-R1</em>, the first framework to endow a moderate-sized (3B-parameter) LLM with comprehensive temporal abilities: understanding, prediction, and creative generation. Our approach features a novel three-stage development path; the first two constitute a <em>reinforcement learning (RL) curriculum</em> driven by a meticulously designed dynamic rule-based reward system. This framework progressively builds (1) foundational temporal understanding and logical event-time mappings from historical data, (2) future event prediction skills for events beyond its knowledge cutoff, and finally (3) enables remarkable generalization to creative future scenario generation without any fine-tuning. Strikingly, experiments demonstrate that Time-R1 outperforms models over 200 times larger, including the state-of-the-art 671B DeepSeek-R1, on highly challenging future event prediction and creative scenario generation benchmarks. This work provides strong evidence that thoughtfully engineered, progressive RL fine-tuning allows smaller, efficient models to achieve superior temporal performance, offering a practical and scalable path towards truly time-aware AI. To foster further research, we also release <em><a href="https://huggingface.co/datasets/ulab-ai/Time-Bench" rel="external nofollow noopener" target="_blank">Time-Bench</a></em>, a large-scale multi-task temporal reasoning dataset derived from 10 years of news data, and our series of <em><a href="https://huggingface.co/collections/ulab-ai/time-r1-682626aea47cb2b876285a16" rel="external nofollow noopener" target="_blank">Time-R1</a></em> checkpoints.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">liu2025time</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Time-R1: Towards Comprehensive Temporal Reasoning in LLMs}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Zijia and Han, Peixuan and Yu, Haofei and Li, Haoru and You, Jiaxuan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2505.13508}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <img src="/assets/img/publication_preview/SafeScientist.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="SafeScientist.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhu2025safescientist" class="col-sm-8"> <div class="title">SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents</div> <div class="author"> Kunlun Zhu<sup>*</sup>, Jiaxun Zhang<sup>*</sup>, Ziheng Qi<sup>*</sup>, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Nuoxing Shang&lt;sup&gt;*&lt;/sup&gt;, Zijia Liu, Peixuan Han, Yue Su, Haofei Yu, Jiaxuan You' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2505.23559</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://arxiv.org/abs/2505.23559" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Recent advancements in large language model (LLM) agents have significantly accelerated scientific discovery automation, yet concurrently raised critical ethical and safety concerns. To systematically address these challenges, we introduce <strong>SafeScientist</strong>, an innovative AI scientist framework explicitly designed to enhance safety and ethical responsibility in AI-driven scientific exploration. SafeScientist proactively refuses ethically inappropriate or high-risk tasks and rigorously emphasizes safety throughout the research process. To achieve comprehensive safety oversight, we integrate multiple defensive mechanisms, including prompt monitoring, agent-collaboration monitoring, tool-use monitoring, and an ethical reviewer component. Complementing SafeScientist, we propose <strong>SciSafetyBench</strong>, a novel benchmark specifically designed to evaluate AI safety in scientific contexts, comprising 240 high-risk scientific tasks across 6 domains, alongside 30 specially designed scientific tools and 120 tool-related risk tasks. Extensive experiments demonstrate that SafeScientist significantly improves safety performance by 35% compared to traditional AI scientist frameworks, without compromising scientific output quality. Additionally, we rigorously validate the robustness of our safety pipeline against diverse adversarial attack methods, further confirming the effectiveness of our integrated approach. The code and data will be available at <a href="https://github.com/ulab-uiuc/SafeScientist" rel="external nofollow noopener" target="_blank">https://github.com/ulab-uiuc/SafeScientist</a>. <span style="color: red;">Warning: this paper contains example data that may be offensive or harmful.</span></p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhu2025safescientist</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SafeScientist: Toward Risk-Aware Scientific Discoveries by LLM Agents}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhu, Kunlun and Zhang, Jiaxun and Qi, Ziheng and Shang, Nuoxing and Liu, Zijia and Han, Peixuan and Su, Yue and Yu, Haofei and You, Jiaxuan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2505.23559}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">PRX</abbr> <figure> <picture> <img src="/assets/img/publication_preview/predictor.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="predictor.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="liu2024early" class="col-sm-8"> <div class="title">Early predictor for the onset of critical transitions in networked dynamical systems</div> <div class="author"> <strong>Zijia Liu</strong>, Xiaozhu Zhang, Xiaolei Ru, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Ting-Ting Gao, Jack Murdoch Moore, Gang Yan' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Physical Review X</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"><strong><span style="color: red;">Highlights</span></strong></a> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://journals.aps.org/prx/abstract/10.1103/PhysRevX.14.031009" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://drive.google.com/file/d/1sDMI-sh7X74hH4MYA5blIANLLqnqEwle/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/m-serious/tipping-predictor" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://drive.google.com/file/d/1-m7EBBXrxJjmxmEkuh4uLoMn_2F-V7PK/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> <a href="https://www.nature.com/articles/s41567-024-02623-9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Coverage</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>The article was featured in both <strong><a href="https://www.nature.com/articles/s41567-024-02623-9" rel="external nofollow noopener" target="_blank">Nature Physics</a></strong> and <strong><a href="https://physics.aps.org/articles/v17/110" rel="external nofollow noopener" target="_blank">Physics</a></strong>, with dedicated coverage in each.</p> </div> <div class="abstract hidden"> <p>Numerous natural and human-made systems exhibit critical transitions whereby slow changes in environmental conditions spark abrupt shifts to a qualitatively distinct state. These shifts very often entail severe consequences; therefore, it is imperative to devise robust and informative approaches for anticipating the onset of critical transitions. Real-world complex systems can comprise hundreds or thousands of interacting entities, and implementing prevention or management strategies for critical transitions requires knowledge of the exact condition in which they will manifest. However, most research so far has focused on low-dimensional systems and small networks containing fewer than ten nodes or has not provided an estimate of the location where the transition will occur. We address these weaknesses by developing a deep-learning framework which can predict the specific location where critical transitions happen in networked systems with size up to hundreds of nodes. These predictions do not rely on the network topology, the edge weights, or the knowledge of system dynamics. We validate the effectiveness of our machine-learning-based framework by considering a diverse selection of systems representing both smooth (second-order) and explosive (first-order) transitions: the synchronization transition in coupled Kuramoto oscillators; the sharp decline in the resource biomass present in an ecosystem; and the abrupt collapse of a Wilson-Cowan neuronal system. We show that our method provides accurate predictions for the onset of critical transitions well in advance of their occurrences, is robust to noise and transient data, and relies only on observations of a small fraction of nodes. Finally, we demonstrate the applicability of our approach to real-world systems by considering empirical vegetated ecosystems in Africa.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">liu2024early</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Early predictor for the onset of critical transitions in networked dynamical systems}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Zijia and Zhang, Xiaozhu and Ru, Xiaolei and Gao, Ting-Ting and Moore, Jack Murdoch and Yan, Gang}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Physical Review X}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{031009}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{APS}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <figure> <picture> <img src="/assets/img/publication_preview/attention.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="attention.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ru2023attentive" class="col-sm-8"> <div class="title">Attentive transfer entropy to exploit transient emergence of coupling effect</div> <div class="author"> Xiaolei Ru, Xinya Zhang, <strong>Zijia Liu</strong>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jack Murdoch Moore, Gang Yan' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button"><strong><span style="color: red;">Spotlight</span></strong></a> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/00bb4e415ef117f2dee2fc3b778d806d-Abstract-Conference.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://neurips.cc/virtual/2023/poster/72043" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/ganglab/attentive_ten" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://drive.google.com/file/d/1qH4zM8dZqaHMn-tpUOFuMuAGkUlGyiHY/view?usp=sharing" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Slides</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>This paper was selected as <strong><a href="https://neurips.cc/virtual/2023/poster/72043" rel="external nofollow noopener" target="_blank">Spotlight</a></strong> at NeurIPS 2023.</p> </div> <div class="abstract hidden"> <p>We consider the problem of reconstructing coupled networks (e.g., biological neural networks) connecting large numbers of variables (e.g., nerve cells) for which state evolution is governed by dissipative dynamics consisting of strong self-drive which dominates the evolution and weak coupling-drive. The core difficulty is sparseness of coupling effect, which emerges with significant coupling force only momentarily and otherwise remains quiescent in time series (e.g., neuronal activity sequence). Here we propose an attention mechanism to guide the classifier to make inference focusing on the critical regions of time series data where coupling effect may manifest. Specifically, attention coefficients are assigned autonomously by artificial neural networks trained to maximise the Attentive Transfer Entropy (ATEn), which is a novel generalization of the iconic transfer entropy metric. Our results show that, without any prior knowledge of dynamics, ATEn explicitly identifies areas where the strength of coupling-drive is distinctly greater than zero. This innovation substantially improves reconstruction performance for both synthetic and real directed coupling networks using data generated by neuronal models widely used in neuroscience.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ru2023attentive</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Attentive transfer entropy to exploit transient emergence of coupling effect}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ru, Xiaolei and Zhang, Xinya and Liu, Zijia and Moore, Jack Murdoch and Yan, Gang}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{171--183}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%7A%6C%69%75%33%33%31@%69%6C%6C%69%6E%6F%69%73.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://www.linkedin.com/in/zijia-liu-771137334/" title="LinkedIn" rel="external nofollow noopener" target="_blank"> <img src="/assets/img/linkin.png" alt="LinkedIn"> </a> <a href="https://scholar.google.com/citations?user=17f5_L4AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/m-serious" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://huggingface.co/m-serious" title="Hugging Face" rel="external nofollow noopener" target="_blank"> <svg> <image xlink:href="https://huggingface.co/front/assets/huggingface_logo-noborder.svg"></image> </svg> </a> <a href="https://twitter.com/xwzliuzijia" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note">Feel free to reach out! I'm always open to discussing new ideas, collaborations, and jobs. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Zijia Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">a nice theme</a>. Last updated: June 23, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>